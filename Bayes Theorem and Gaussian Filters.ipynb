{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' Theorem and Gaussian Filters #\n",
    "\n",
    "### Jack Nelson, April 2016 ###\n",
    "\n",
    "In this notebook, I establish the theoretical groundwork for Gaussian filtering, one of the most popular and important tools in autonomous (robotic) localization. The defining characteristic of Gaussian filtering techniques is the use of Gaussian normal distributions to model the **location and uncertainty** of an autonomous agent (aka a robot). \n",
    "\n",
    "The fundamental idea behind Gaussian filtering is the incorporation of uncertainty into a robot's perception of its environment and its location within that environment. You can't always know *exactly* where you are, especially when you have sensors (eyes, ears, a compass, gps satnav) that aren't 100% correct. Gaussian filtering acknowledges this shortcoming of a robot's ability to have exact information about its location and embraces it.\n",
    "\n",
    "Using the fundamental concepts of probability and the properties of Gaussian distributions, we'll derive the foundation of Gaussian filtering: Bayes' theorem. This theorem describes how to incorporate measurements from our sensors and the control inputs to our robot to probabalistically model our robot's state (i.e. its location and velocity), as well as recursively update our robot's estimation of its state using new measurement and control information.\n",
    "\n",
    "### A Short Gedankenexperiment (with pizza) ###\n",
    "\n",
    "To illustrate the spirit behind Gaussian filtering algorithms, let's start with a quick thought experiment. Imagine a friend picks you up in their car at your house to go get pizza at a restaurant you've never been to. You buckle into the passenger seat and your friend hands you a menu for the pizza place you're going to. You spend the entire fifteen minute ride enraptured by the pamphlet-sized pizza menu, tortured over the agonizing choice between veggie supreme or meat lover's. \n",
    "\n",
    "Finally your friend parks the car in front of the restaurant and you look up for the first time since you got in the car. You have no idea where you are, though you do know you were only in the car for fifteen minutes. You draw a mental map of your local neighborhood. You must be someplace within fifteen minutes driving-time of your house, so you plant a marker on your home and draw out a circle around it whose radius is roughly the distance fifteen minutes of driving would take you. You must be somewhere in that circle.\n",
    "\n",
    "You begin looking around at your settings. You've parked on a major avenue, and there are only one of these in your fifteen minute circle. You move the center of your circle to the place on the avenue closest to your home, about a five minute drive away, and redraw the radius to a ten minute drive.\n",
    "\n",
    "As you continue looking around at your surroundings for landmarks you recognize, you automatically update and redraw your mental map of your location. Each observation helps you decrease your uncertainty as to where you are (that is, the size of the circle around your potential location).\n",
    "\n",
    "In a matter of a few seconds, you're probably able to localize yourself from the surrounding landmarks, essentially reducing your uncertainty to near zero. This entire process, which everyone goes through just about every day whether they realize it or not, happens remarkably quickly with humans without having to think too hard about it. \n",
    "\n",
    "We can break this localization process down into a very general algorithm:\n",
    "\n",
    "```\n",
    "1 Initialize an internal belief of location with a large uncertainty (variance).\n",
    "2 While uncertainty in location belief is high:\n",
    "3     Make an observation of the environment and look for landmarks.\n",
    "4     Update internal belief of location. Reduce uncertainty in location.\n",
    "```\n",
    "\n",
    "Though you never work with Gaussian normal distributions in your head, this algorithm is essentially a type of Gaussian filter. Since there is uncertainty in your location, your mental model of your position places you in a \"most likely\" mean position with some variance or \"uncertainty\" that you try to iteratively reduce.\n",
    "\n",
    "This algorithm, while easy and intuitive for humans, gets very thorny very quickly for robots. Finding out where you are in an environment is a fundamental problem in robotics and is referred to generally as the **problem of localization**. We will be learning how to make a robot localize itself in its environment using Gaussian filtering. Before we write any executable code, however, we must lay the foundation for Gaussian filtering.\n",
    "\n",
    "### \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
